{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implementing the network structure from the paper https://arxiv.org/abs/1704.02019\n",
    "# Associative Content Addressable Memory with Exponentially Many Robust Stable States\n",
    "# By Rishidev Chaudhuri and Ila Fiete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Goint in to really solve the oscillation issue\n",
    "# I suspect the issue is this: http://www.robertmarks.org/REPRINTS/1987_SynchronousVsAsynchonousBehavior.pdf\n",
    "# I am going to try to fix it with asynchronous operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adammarblestone/Library/Enthought/Canopy_64bit/User/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.cm as cm # color maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_num_timesteps = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Bottom layer has N neurons, called input neurons\n",
    "# Second layer is constraint layer, has N_c ~ N small sub-networks\n",
    "# The small sub-networks are called constraint nodes\n",
    "# ith input neuron connects to z_i constraint nodes\n",
    "# jth constraint node connects to z_j_c input neurons\n",
    "\n",
    "# Each neuron in a given constraint node is connected to the same set of input neurons\n",
    "\n",
    "# M is the number of neurons in each constraint node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matching_assignment(N, N_c, z, z_c): # A more correct way to get z = [user specified] and z_c < constant\n",
    "\n",
    "    if N_c * z_c != N * z:\n",
    "        print \"MISMATCHED SIZES\"\n",
    "\n",
    "    outgoing_edges_left = []\n",
    "    for i in range(N):\n",
    "        for j in range(z):\n",
    "            outgoing_edges_left.append((i,\"?\"))\n",
    "\n",
    "    incoming_edges_right = []\n",
    "    for k in range(N_c):\n",
    "        for l in range(z_c):\n",
    "            incoming_edges_right.append((\"?\", k))\n",
    "\n",
    "    matches = []\n",
    "    while len(matches) < N*z:\n",
    "        random_index_left = np.random.randint(0, len(outgoing_edges_left), size=1)[0]\n",
    "        random_index_right = np.random.randint(0, len(incoming_edges_right), size=1)[0]\n",
    "        s = (outgoing_edges_left[random_index_left][0], incoming_edges_right[random_index_right][1])\n",
    "        if not s in matches:\n",
    "            matches.append(s)\n",
    "            outgoing_edges_left.pop(random_index_left)\n",
    "            incoming_edges_right.pop(random_index_right)\n",
    "            \n",
    "    input_to_constraint_node_connectivity = []\n",
    "    for n in range(N):\n",
    "        outgoing = []\n",
    "        for o in matches:\n",
    "            if o[0] == n:\n",
    "                outgoing.append(o[1])\n",
    "        input_to_constraint_node_connectivity.append(outgoing)\n",
    "        \n",
    "    return input_to_constraint_node_connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N = 36\n",
      "N_c = 15\n",
      "z = 5\n",
      "z_c_avg = 12\n",
      "r = 5\n",
      "M_typical = 128\n"
     ]
    }
   ],
   "source": [
    "# First define the input to constraint node connectivity\n",
    "\n",
    "N = 36 # Should be a multiple of 12\n",
    "print \"N = %i\" % N\n",
    "\n",
    "N_c = int(5*N/12)\n",
    "print \"N_c = %i\" % N_c\n",
    "\n",
    "z = 5\n",
    "print \"z = %i\" % z\n",
    "\n",
    "z_c_avg = int(N*z/N_c)\n",
    "print \"z_c_avg = %i\" % z_c_avg\n",
    "\n",
    "r = 5\n",
    "print \"r = %i\" % r\n",
    "\n",
    "M_typical = 2**(z_c_avg-r)\n",
    "print \"M_typical = %i\" % M_typical\n",
    "\n",
    "input_to_constraint_node_connectivity = matching_assignment(N, N_c, z, z_c_avg)\n",
    "    \n",
    "constraint_node_to_input_connectivity = []\n",
    "for i in range(N_c):\n",
    "    temp = []\n",
    "    for j in range(N):\n",
    "        if i in input_to_constraint_node_connectivity[j]:\n",
    "            temp.append(j)\n",
    "    constraint_node_to_input_connectivity.append(temp)\n",
    "    \n",
    "plt.figure()\n",
    "plt.title(\"z histogram: should be all at 5\")\n",
    "plt.xlabel(\"outgoing edges\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.hist([len(q) for q in input_to_constraint_node_connectivity])\n",
    "plt.show()\n",
    "\n",
    "print \"\\ntotal outgoing edges\"\n",
    "print np.sum([len(q) for q in input_to_constraint_node_connectivity])\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"z_c histogram: should all be 12\")\n",
    "plt.xlabel(\"incoming edges to constraint node\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.hist([len(q) for q in constraint_node_to_input_connectivity])\n",
    "plt.show()\n",
    "\n",
    "print \"\\ntotal incoming edges\"\n",
    "print np.sum([len(q) for q in constraint_node_to_input_connectivity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_random_parity_states(input_size, num_parity_states_to_generate):\n",
    "    parity_states = []\n",
    "    for i in range(num_parity_states_to_generate):\n",
    "        parity = 1\n",
    "        state = []\n",
    "        while parity == 1:\n",
    "            state = np.random.randint(0,2,size = input_size)\n",
    "            parity = sum(state) % 2\n",
    "            if parity == 0:\n",
    "                parity_states.append(state)\n",
    "\n",
    "    return parity_states\n",
    "\n",
    "print generate_random_parity_states(12, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def M_for_constraint_node(constraint_node_index):\n",
    "    z_c_for_this_node = len(constraint_node_to_input_connectivity[constraint_node_index])\n",
    "    return 2**(z_c_for_this_node - r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_constraint_node_neurons(constraint_node_index):\n",
    "    neurons = []\n",
    "    z_c_for_this_node = len(constraint_node_to_input_connectivity[constraint_node_index])\n",
    "    M_for_this_node = M_for_constraint_node(constraint_node_index)\n",
    "    for i in range(M_for_this_node):\n",
    "        neuron = {}\n",
    "        neuron[\"inputs\"] = constraint_node_to_input_connectivity[constraint_node_index]\n",
    "        neuron[\"num_inputs\"] = len(neuron[\"inputs\"])\n",
    "        neuron[\"preferred_parity_config\"] = generate_random_parity_states(neuron[\"num_inputs\"], 1)[0]\n",
    "        neuron[\"ons_preferred\"] = [neuron[\"inputs\"][j] for j in range(neuron[\"num_inputs\"]) if neuron[\"preferred_parity_config\"][j] == 1] \n",
    "        neuron[\"offs_preffered\"] = [neuron[\"inputs\"][j] for j in range(neuron[\"num_inputs\"]) if neuron[\"preferred_parity_config\"][j] == 0]\n",
    "        neuron[\"bias_term\"] = neuron[\"num_inputs\"] - np.sum(neuron[\"preferred_parity_config\"])\n",
    "        neurons.append(neuron)\n",
    "\n",
    "    return neurons\n",
    "\n",
    "print generate_constraint_node_neurons(N_c-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_full_index(constraint_node_index, index_within_node):\n",
    "    return N + sum([M_for_constraint_node(k) for k in range(constraint_node_index)]) + index_within_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generating the full weight matrix and biases\n",
    "\n",
    "last_constraint_node_index = N_c-1\n",
    "\n",
    "last_neuron_in_last_constraint_node_index = M_for_constraint_node(last_constraint_node_index) - 1\n",
    "\n",
    "total_number_neurons = get_full_index(last_constraint_node_index, last_neuron_in_last_constraint_node_index) + 1\n",
    "total_number_neurons = int(total_number_neurons) # Not sure why it is making me do this\n",
    "print \"total number of neurons %i\" % total_number_neurons\n",
    " \n",
    "full_weight_matrix = [[0.0 for j in range(total_number_neurons)] for i in range(total_number_neurons)]\n",
    "\n",
    "biases = [0.0 for j in range(total_number_neurons)]\n",
    "\n",
    "for node in range(N_c): # Index over constraint nodes\n",
    "    neurons_in_node = generate_constraint_node_neurons(node) # Generate neurons in that constraint node\n",
    "    z_c_for_this_node = len(constraint_node_to_input_connectivity[node])\n",
    "    M_for_this_node = M_for_constraint_node(node)\n",
    "    for m in range(M_for_this_node):\n",
    "        neuron_full_index = get_full_index(node, m)\n",
    "        neuron = neurons_in_node[m]\n",
    "        for g in neuron[\"ons_preferred\"]: # Constraint neuron to input neuron and vice versa\n",
    "            full_weight_matrix[neuron_full_index][g] = 1\n",
    "            full_weight_matrix[g][neuron_full_index] = 1\n",
    "        for g in neuron[\"offs_preffered\"]: # Constraint neuron to input neuron and vice versa\n",
    "            full_weight_matrix[neuron_full_index][g] = -1\n",
    "            full_weight_matrix[g][neuron_full_index] = -1\n",
    "        for p in range(m, M_for_this_node): # Inhibitory internal connectivity within the same node\n",
    "            p_full_index = get_full_index(node, p)\n",
    "            if p != m:\n",
    "                full_weight_matrix[neuron_full_index][p_full_index] = -1*(neuron[\"num_inputs\"] - 1)\n",
    "                full_weight_matrix[p_full_index][neuron_full_index] =  -1*(neuron[\"num_inputs\"] - 1)\n",
    "        biases[neuron_full_index] = neuron[\"bias_term\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 12)\n",
    "plt.figure()\n",
    "plt.title(\"Full weight matrix\")\n",
    "plt.imshow(full_weight_matrix, interpolation='none')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Full weight matrix: zooming in on corner\")\n",
    "corner = full_weight_matrix[:50][:50]\n",
    "plt.imshow(corner, interpolation='none')\n",
    "plt.xlim(0.0, 50.0)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (7, 7)\n",
    "plt.figure()\n",
    "plt.title(\"Neuron biases\")\n",
    "plt.xlabel(\"Neuron indices\")\n",
    "plt.ylabel(\"Bias term\")\n",
    "plt.plot(biases)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Defining some Hopfield aspects\n",
    "\n",
    "def random_state(num_neurons):\n",
    "    return np.random.randint(0,2,size = num_neurons)\n",
    "\n",
    "def time_step(state, weight_matrix, biases): # Asynchronous mode\n",
    "\n",
    "    k = np.random.randint(0, len(state), size=1)[0] # Pick a random single neuron to update\n",
    "    \n",
    "    a = 0.0\n",
    "    for j in range(len(state)):\n",
    "        if j != k:\n",
    "            a += weight_matrix[k][j] * state[j]\n",
    "    a += biases[k]\n",
    "        \n",
    "    ns = state\n",
    "        \n",
    "    if a > 0.0:\n",
    "        ns[k] = 1.0\n",
    "    elif a < 0.0:\n",
    "        ns[k] = 0.0\n",
    "    elif a == 0.0: # If the activation is exactly zero\n",
    "        coin_flip = float(np.random.randint(0,2, size=1)[0])\n",
    "        ns[k] = coin_flip\n",
    "                        \n",
    "    return ns\n",
    "\n",
    "def energy(s, weights, bias):\n",
    "    s_plusminus = [(-1)**q for q in s]\n",
    "    x = np.array(s_plusminus)\n",
    "    W = np.array(weights)\n",
    "    b = np.array(bias)\n",
    "    E = (1/2)*np.matmul(np.matmul(np.transpose(x), W), x) + np.dot(x,b)\n",
    "    return E\n",
    "\n",
    "def small_perturbation(perturb_size, state):\n",
    "    new_state = np.zeros(len(state))\n",
    "    prob = float(perturb_size)/float(len(state))\n",
    "    for i in range(len(state)):\n",
    "        if np.random.rand() < prob:\n",
    "            new_state[i] = (state[i] + 1) % 2\n",
    "        else:\n",
    "            new_state[i] = state[i]\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test out some Hopfield dynamics\n",
    "initial_random_state = random_state(total_number_neurons)\n",
    "\n",
    "num_timesteps = global_num_timesteps\n",
    "state = initial_random_state\n",
    "energies = []\n",
    "e = energy(state, full_weight_matrix, biases)\n",
    "print \"energy %f\" % e, state[:2*N]\n",
    "for i in range(num_timesteps):\n",
    "    new_state = time_step(state, full_weight_matrix, biases)\n",
    "    e = energy(new_state, full_weight_matrix, biases)\n",
    "    energies.append(e)\n",
    "    state = new_state\n",
    "print \"energy %f\" % e, new_state[:2*N]\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"Hopfield energy function\")\n",
    "plt.title(\"Initial settling\")\n",
    "plt.plot(energies)\n",
    "\n",
    "print \"\\n___Recovery from Perturbation___\"\n",
    "perturb_percent = 4.0\n",
    "print \"Percentage perturbed: %f\" % perturb_percent\n",
    "perturbed_state = small_perturbation(perturb_percent * total_number_neurons / 100.0, state)\n",
    "num_timesteps = global_num_timesteps\n",
    "state = perturbed_state\n",
    "energies = []\n",
    "e = energy(state, full_weight_matrix, biases)\n",
    "print \"energy %f\" % e, state[:2*N]\n",
    "for i in range(num_timesteps):\n",
    "    new_state = time_step(state, full_weight_matrix, biases)\n",
    "    e = energy(new_state, full_weight_matrix, biases)\n",
    "    energies.append(e)\n",
    "    state = new_state\n",
    "print \"energy %f\" % e, new_state[:2*N]\n",
    "\n",
    "plt.figure()\n",
    "plt.xlabel(\"step\")\n",
    "plt.ylabel(\"Hopfield energy function\")\n",
    "plt.title(\"Recovery from perturbation\")\n",
    "plt.plot(energies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
